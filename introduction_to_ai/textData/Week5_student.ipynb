{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in csv file and create Dataframe & check shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html><h2>What is nlp??? </h2></html> \\nNatural Language Processing, or NLP for short, is broadly defined as the automatic manipulation of natural language, like speech and text, by software.\\nThe study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers.\\n(In this post), you will discover what natural language processing is and why it is so important.\\nAfter reading this post, you will know => What natural language is and how it is different from other types of data.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_data = \"\"\"<html><h2>What is nlp??? </h2></html> \n",
    "Natural Language Processing, or NLP for short, is broadly defined as the automatic manipulation of natural language, like speech and text, by software.\n",
    "The study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers.\n",
    "(In this post), you will discover what natural language processing is and why it is so important.\n",
    "After reading this post, you will know => What natural language is and how it is different from other types of data.\"\"\"\n",
    "str_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Cleaning - Remove HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is nlp???  \n",
      "Natural Language Processing, or NLP for short, is broadly defined as the automatic manipulation of natural language, like speech and text, by software.\n",
      "The study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers.\n",
      "(In this post), you will discover what natural language processing is and why it is so important.\n",
      "After reading this post, you will know => What natural language is and how it is different from other types of data.\n"
     ]
    }
   ],
   "source": [
    "def remove_html(text_data):\n",
    "    \"\"\"\n",
    "    WRITE THE CODE\n",
    "    \"\"\"\n",
    "\n",
    "    soup = BeautifulSoup(text_data, 'lxml')\n",
    "    return soup.get_text()\n",
    "\n",
    "processed_text = remove_html(str_data)\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Cleaning - Remove punctuation(Íµ¨ÎëêÏ†ê) & Lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation:  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "## Check English's punctuation\n",
    "print('Punctuation: ', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    sent = []\n",
    "    for t in text.split(' '):\n",
    "        no_punct = \"\".join([c for c in t if c not in string.punctuation ])\n",
    "        sent.append(no_punct)\n",
    "    \n",
    "    sentence = \" \".join(s for s in sent)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is nlp  \n",
      "Natural Language Processing or NLP for short is broadly defined as the automatic manipulation of natural language like speech and text by software\n",
      "The study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers\n",
      "In this post you will discover what natural language processing is and why it is so important\n",
      "After reading this post you will know  What natural language is and how it is different from other types of data\n"
     ]
    }
   ],
   "source": [
    "rmv_punc_sentence = remove_punctuation(processed_text)\n",
    "print(rmv_punc_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is nlp  \n",
      "natural language processing or nlp for short is broadly defined as the automatic manipulation of natural language like speech and text by software\n",
      "the study of natural language processing has been around for more than 50 years and grew out of the field of linguistics with the rise of computers\n",
      "in this post you will discover what natural language processing is and why it is so important\n",
      "after reading this post you will know  what natural language is and how it is different from other types of data\n"
     ]
    }
   ],
   "source": [
    "lower_sentence = rmv_punc_sentence.lower()\n",
    "print(lower_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Lemmatization & Tokenization with spacy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using \"spacy\" library\n",
    "import spacy\n",
    "\n",
    "## Load the installed model \"en_core_web_sm\" into \"nlp\"\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 'doc' is a sequence of Token objects \n",
    "## it holds all information about the tokens, their linguistic features and their relationships.\n",
    "doc = nlp(lower_sentence.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'what'),\n",
       " ('is', 'be'),\n",
       " ('nlp', 'nlp'),\n",
       " (' \\n', ' \\n'),\n",
       " ('natural', 'natural'),\n",
       " ('language', 'language'),\n",
       " ('processing', 'processing'),\n",
       " ('or', 'or'),\n",
       " ('nlp', 'nlp'),\n",
       " ('for', 'for'),\n",
       " ('short', 'short'),\n",
       " ('is', 'be'),\n",
       " ('broadly', 'broadly'),\n",
       " ('defined', 'define'),\n",
       " ('as', 'as')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_lem_sentence = [(token.text, token.lemma_) for token in doc ]\n",
    "tok_lem_sentence[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what',\n",
       " 'be',\n",
       " 'nlp',\n",
       " ' \\n',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'or',\n",
       " 'nlp',\n",
       " 'for',\n",
       " 'short',\n",
       " 'be',\n",
       " 'broadly',\n",
       " 'define',\n",
       " 'as']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_lem_sentence = [token.lemma_ for token in doc]\n",
    "tok_lem_sentence[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Remove stop words(Î∂àÏö©Ïñ¥: ÌÅ∞ ÏùòÎØ∏Í∞Ä ÏóÜÎäî Îã®Ïñ¥)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/chu-\n",
      "[nltk_data]     ingyu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you do not have 'stopwords' then run the below statement.\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'be', 'nlp', ' \\n', 'natural', 'language', 'processing', 'or', 'nlp', 'for', 'short', 'be', 'broadly', 'define', 'as', 'the', 'automatic', 'manipulation', 'of', 'natural', 'language', 'like', 'speech', 'and', 'text', 'by', 'software', '\\n', 'the', 'study', 'of', 'natural', 'language', 'processing', 'have', 'be', 'around', 'for', 'more', 'than', '50', 'year', 'and', 'grow', 'out', 'of', 'the', 'field', 'of', 'linguistic', 'with', 'the', 'rise', 'of', 'computer', '\\n', 'in', 'this', 'post', 'you', 'will', 'discover', 'what', 'natural', 'language', 'processing', 'be', 'and', 'why', 'it', 'be', 'so', 'important', '\\n', 'after', 'read', 'this', 'post', 'you', 'will', 'know', ' ', 'what', 'natural', 'language', 'be', 'and', 'how', 'it', 'be', 'different', 'from', 'other', 'type', 'of', 'datum'] \n",
      "\n",
      "['nlp', ' \\n', 'natural', 'language', 'processing', 'nlp', 'short', 'broadly', 'define', 'automatic', 'manipulation', 'natural', 'language', 'like', 'speech', 'text', 'software', '\\n', 'study', 'natural', 'language', 'processing', 'around', '50', 'year', 'grow', 'field', 'linguistic', 'rise', 'computer', '\\n', 'post', 'discover', 'natural', 'language', 'processing', 'important', '\\n', 'read', 'post', 'know', ' ', 'natural', 'language', 'different', 'type', 'datum']\n",
      "\n",
      "Removed word:  {'or', 'this', 'other', 'from', 'it', 'of', 'in', 'after', 'for', 'so', 'as', 'by', 'why', 'more', 'will', 'the', 'than', 'you', 'and', 'be', 'out', 'have', 'what', 'with', 'how'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "print(tok_lem_sentence, '\\n')\n",
    "rmv_sw_sentence = [w for w in tok_lem_sentence if not w in stop_words]\n",
    "print(rmv_sw_sentence)\n",
    "removed_word = [word for word in tok_lem_sentence if not word in rmv_sw_sentence]\n",
    "print(\"\\nRemoved word: \", set(removed_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Make dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dictionary = {}\n",
    "\n",
    "def make_frequency_dict(text):\n",
    "    \"\"\"\n",
    "    WRITE THE CODE\n",
    "    \"\"\"\n",
    "            \n",
    "make_frequency_dict(rmv_sw_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sorted = sorted(dictionary.items(), key=lambda x:x[1], reverse = True)\n",
    "vocab_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {}\n",
    "i = 0\n",
    "\n",
    "for (word, frequency) in vocab_sorted :\n",
    "    \"\"\"\n",
    "    WRITE THE CODE\n",
    "    \"\"\"\n",
    "    \n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "WRITE THE CODE\n",
    "\"\"\"\n",
    "\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = []\n",
    "\n",
    "print(rmv_sw_sentence)\n",
    "\n",
    "for w in rmv_sw_sentence:\n",
    "    \"\"\"\n",
    "    WRITE THE CODE\n",
    "    \"\"\"\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE END üåü"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
